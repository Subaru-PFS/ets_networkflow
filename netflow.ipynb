{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go wide screen\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(s):\n",
    "    print(s)\n",
    "    return s + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datamodel for the flow network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add current working directory to pythonpath\n",
    "import sys\n",
    "sys.path.append(\"/Users/mxhf/ownCloudRZG/work/MPE/pfs/ETS/real_test\")\n",
    "\n",
    "# Next two lines forc outomatic reload of loaded module. Convenient if\n",
    "# one is still fiddeling with them.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pfs_netflow.datamodel as dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the catalogs, compute visibility ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BLOCKLENGTH = 300. # block exposure time in s, to simulate three consequtive exposures\n",
    "BLOCKLENGTH = 900. # block exposure time in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target lists.\n",
    "fscience_targets = \"../../ETS/pfs_target_list/pfs_preliminary_target_cosmology.dat\"\n",
    "fcal_stars       = \"../../ETS/pfs_target_list/pfs_preliminary_target_cosmology_fcstars.dat\"\n",
    "fsky_pos         = \"../../ETS/pfs_target_list/pfs_preliminary_target_cosmology_sky.dat\"\n",
    "\n",
    "# Load target lists.\n",
    "from astropy.io import ascii\n",
    "\n",
    "science_targets = ascii.read(fscience_targets)\n",
    "\n",
    "cal_stars = ascii.read(fcal_stars)\n",
    "\n",
    "sky_pos = ascii.read(fsky_pos)\n",
    "\n",
    "# Conversion of column names, this should not be necessary anymore in future versions.\n",
    "for t in [science_targets, cal_stars, sky_pos]:\n",
    "    t['R'].name = 'RA'\n",
    "    t['Dec'].name = 'DEC'\n",
    "    t['Exposure'].name = 'EXP_TIME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to lists for ETS.\n",
    "import numpy as np\n",
    "from numpy import hstack\n",
    "from numpy import cos, deg2rad, sqrt\n",
    "from numpy import unique, array\n",
    "\n",
    "\n",
    "ID         = hstack([science_targets['ID'],cal_stars['ID'],sky_pos['ID']])\n",
    "ra         = hstack([science_targets['RA'],cal_stars['RA'],sky_pos['RA']])\n",
    "dec        = hstack([science_targets['DEC'],cal_stars['DEC'],sky_pos['DEC']])\n",
    "exp_times  = hstack([science_targets['EXP_TIME'],cal_stars['EXP_TIME'],sky_pos['EXP_TIME']])\n",
    "priorities = hstack([science_targets['Priority'],cal_stars['Priority'],sky_pos['Priority']])\n",
    "\n",
    "# make up target classes from target type and priority\n",
    "types = [\"sci\"]*len(science_targets) + [\"cal\"]*len(cal_stars) + [\"sky\"]*len(sky_pos)\n",
    "class_dict = {}\n",
    "for id,t,p in zip(ID, types, priorities):\n",
    "    class_dict[id] = '{}_P{}'.format(t, p)\n",
    "    \n",
    "# limit targets to a smaller field of view\n",
    "pointing_RA, pointing_DEC = 33.7025, -3.8455\n",
    "\n",
    "DRMAX_SQ = .75**2\n",
    "DRMAX_SQ = .02**2\n",
    "DRMAX_SQ = (2700./3600.)**2.\n",
    "#DRMAX_SQ = .5**2\n",
    "\n",
    "dra = (ra - pointing_RA)*cos(deg2rad(dec))\n",
    "ddec = dec - pointing_DEC\n",
    "ii = (dra**2. + ddec **2.) <= DRMAX_SQ\n",
    "\n",
    "ID = ID[ii].tolist()\n",
    "ra = ra[ii].tolist()\n",
    "dec = dec[ii].tolist()\n",
    "exp_times = exp_times[ii].tolist()\n",
    "priorities = priorities[ii].tolist()\n",
    "types = np.array(types)[ii].tolist()\n",
    "\n",
    "c = np.array([ class_dict[t][:3] for t in ID ])\n",
    "ii_sci = c == 'sci'\n",
    "ii_cal = c == 'cal'\n",
    "ii_sky = c == 'sky'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign random priorities between 1 and 3 for the  science targets\n",
    "from numpy import random\n",
    "from numpy import array\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "N =  sum(ii_sci) \n",
    "\n",
    "newpri = array( random.uniform(1.,4., size=N) , dtype=int)\n",
    "priorities = np.array(priorities)\n",
    "\n",
    "priorities[ii_sci] = newpri\n",
    "priorities = priorities.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute number of required visists from exposure times\n",
    "# and block length\n",
    "nreqv_dict = {}\n",
    "for id,t,nrv in zip(ID, types, array(exp_times)/BLOCKLENGTH):\n",
    "    nreqv_dict[id] = int(nrv)\n",
    "    \n",
    "print \"Required revisits\", unique( [v for v in nreqv_dict.itervalues()] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOMISE NUMBER OF REQUIRED VISISTS\n",
    "RANDOMIZENREQ = True\n",
    "if RANDOMIZENREQ:\n",
    "    NVISITS = 10\n",
    "    nv = np.floor( random.uniform(NVISITS+1, size=len(ID)) ) \n",
    "\n",
    "    # compute number of required visists from exposure times\n",
    "    # and block length\n",
    "    nreqv_dict = {}\n",
    "    for id,t,nrv in zip(ID, types, nv):\n",
    "        nreqv_dict[id] = int(nrv)\n",
    "\n",
    "    print \"Required revisits\", unique( [v for v in nreqv_dict.itervalues()] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.append(\"/Users/mxhf/ownCloudRZG/work/MPE/pfs/src/ets_fiber_assigner\")\n",
    "\n",
    "import pyETS\n",
    "import pycconv\n",
    "\n",
    "# Temporary, very crude method to convert Ra/Dec pairs to x/y coordinates\n",
    "# on the focal plane. To be replaced by the official functionality once\n",
    "# available.\n",
    "# All input angles are expected in degrees.\n",
    "def radec2pos(ras, decs, raTel=None, decTel=None, posang=0.,\n",
    "              time=\"2016-04-03T08:00:00Z\"):\n",
    "    if raTel is None:\n",
    "        raTel = np.average(ras)\n",
    "    if decTel is None:\n",
    "        decTel = np.average(decs)\n",
    "    return pycconv.cconv(ras,decs,raTel,decTel,posang+90.,time)\n",
    "\n",
    "# get a data structure containing the idealized cobras\n",
    "ets_cobras = pyETS.getAllCobras()\n",
    "\n",
    "# Parse a target file and return the quantities of interest\n",
    "ets_target_pos = radec2pos(ra,dec)\n",
    "\n",
    "# get a list of targets, and a list of Cobras that can observe them\n",
    "# keys contain object index\n",
    "# values contain indices of cobras that can observe that object.\n",
    "visibility_map = pyETS.getVis(ets_target_pos, ets_cobras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interface to the new ETS, convert cobras, visibilities and targets to old style format\n",
    "from collections import OrderedDict\n",
    "\n",
    "# obtain cobra centers in old ETS dictionary style\n",
    "cobras = OrderedDict()\n",
    "for i,c in enumerate(ets_cobras):\n",
    "        x,y = np.real( ets_cobras[i][0] ), np.imag( ets_cobras[i][0] )\n",
    "        cobras[\"{:d}\".format(i)] = [x,y]\n",
    "\n",
    "# obtain target positions in old ETS dictionary style\n",
    "targets = OrderedDict()\n",
    "for i,c in enumerate(ets_target_pos):\n",
    "        x,y = np.real(c),np.imag(c)\n",
    "        targets[ID[i]] = [float(x),float(y)]\n",
    "\n",
    "# obtain visibilities in old ETS dictionary style\n",
    "visibilities = OrderedDict()   \n",
    "for v in visibility_map:\n",
    "    t = ID[v]\n",
    "    cc = [\"{:d}\".format(c) for c in visibility_map[v]]\n",
    "    visibilities[t] = cc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    f = plt.figure(figsize=[10,10])\n",
    "    cxx = [c[0] for cid, c in cobras.iteritems()]\n",
    "    cyy = [c[1] for cid, c in cobras.iteritems()]\n",
    "    txx = [t[0] for tid, t in targets.iteritems()]\n",
    "    tyy = [t[1] for tid, t in targets.iteritems()]\n",
    "\n",
    "    if True:\n",
    "        for tid,cc in visibilities.iteritems():\n",
    "            tx,ty = targets[tid]\n",
    "            for c in cc:\n",
    "                cx,cy = cobras[c]\n",
    "                #print c\n",
    "                #plt.text(cx,cy,\"{}\".format(c) )\n",
    "                plt.plot([cx,tx],[cy,ty],'k-')\n",
    "\n",
    "\n",
    "    plt.plot(cxx,cyy,'.')\n",
    "    plt.plot(txx,tyy,'.')\n",
    "\n",
    "    plt.axis('equal')\n",
    "    plt.xlim([-20,20])\n",
    "    plt.ylim([-20,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform target assignment using the \"draining\" algorithm, and return the list\n",
    "# of assigned targets and which cobras were used to observe them.\n",
    "#res = pyETS.getObs(ets_target_pos,exp_times,priorities,ets_cobras,\"draining_closest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign targetclass labels according to target type and priority\n",
    "from numpy import unique\n",
    "\n",
    "# Build dict that holds class descriptor string for each target.\n",
    "# This is needed later because ETS does not preserve the order.\n",
    "tclasses =   np.array( [class_dict[t] for t in targets] )\n",
    "print(unique(tclasses))\n",
    "\n",
    "# Build dict that holds required number of visits each target.\n",
    "nreqvisits = [nreqv_dict[t] for t in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot targets on sky\n",
    "f = plt.figure(figsize=[20,10])\n",
    "plt.subplot(121)\n",
    "plt.plot(np.array(ra)[ii_sci],np.array(dec)[ii_sci],'.', ms=1, label='science')\n",
    "plt.plot(np.array(ra)[ii_sky],np.array(dec)[ii_sky],'b.' , label='sky')\n",
    "plt.plot(np.array(ra)[ii_cal],np.array(dec)[ii_cal],'yo' , label='cal. star')\n",
    "plt.axis('equal')\n",
    "l = plt.legend()\n",
    "l.draw_frame(False)\n",
    "plt.xlabel(\"RA [Deg]\")\n",
    "plt.ylabel(\"DEC [Deg]\")\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "txx = np.array( [t[0] for tid, t in targets.iteritems()] )\n",
    "tyy = np.array( [t[1] for tid, t in targets.iteritems()] )\n",
    "\n",
    "\n",
    "#for tc in unique(tclasses):\n",
    "\n",
    "_ii_sci = map( lambda x : x.startswith('sci') , tclasses )\n",
    "_ii_sky = map( lambda x : x.startswith('sky') , tclasses )\n",
    "_ii_cal = map( lambda x : x.startswith('cal') , tclasses )\n",
    "plt.plot(txx[_ii_sci],tyy[_ii_sci],'.', ms=1, label='science')\n",
    "plt.plot(txx[_ii_sky],tyy[_ii_sky],'b.' , label='sky')\n",
    "plt.plot(txx[_ii_cal],tyy[_ii_cal],'yo' , label='cal. star')\n",
    "\n",
    "#plt.plot(txx[ii_sky],tyy[ii_sky],'b.' , label='sky')\n",
    "#plt.plot(txx[ii_cal],tyy[ii_cal],'yo' , label='cal. star')\n",
    "\n",
    "\n",
    "plt.axis('equal')\n",
    "l = plt.legend()\n",
    "l.draw_frame(False)\n",
    "plt.xlabel(\"x [mm]\")\n",
    "plt.ylabel(\"y [mm]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find collision pairs\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "fiber_collision_radius = 1.\n",
    "\n",
    "\n",
    "f = plt.figure(figsize=[5,5])\n",
    "plt.subplot()\n",
    "txx = np.array( [t[0] for tid, t in targets.iteritems()] )\n",
    "tyy = np.array( [t[1] for tid, t in targets.iteritems()] )\n",
    "\n",
    "_ii_sci = map( lambda x : x.startswith('sci') , tclasses )\n",
    "_ii_sky = map( lambda x : x.startswith('sky') , tclasses )\n",
    "_ii_cal = map( lambda x : x.startswith('cal') , tclasses )\n",
    "\n",
    "\n",
    "plt.plot(txx[_ii_sci],tyy[_ii_sci],'.', ms=1, label='science')\n",
    "plt.plot(txx[_ii_sky],tyy[_ii_sky],'b.' , label='sky')\n",
    "plt.plot(txx[_ii_cal],tyy[_ii_cal],'yo' , label='cal. star')\n",
    "\n",
    "\n",
    "N = len(ID)\n",
    "points = zip(txx,tyy)\n",
    "Y = cdist( points[:N], points[:N] )\n",
    "\n",
    "# any target separation that is smaller than 2 x the collision radius will be flagged a s collision\n",
    "cc = Y <= (fiber_collision_radius*2.) \n",
    "ncoll = int( (np.sum(cc.flatten()) - N)/2. )\n",
    "\n",
    "print (\"Found  {:d} collision pairs.\".format( ncoll  ))\n",
    "\n",
    "# identify collision pairs\n",
    "collision_pairs = []\n",
    "# array of indices\n",
    "ii = np.arange(N)\n",
    "for i in range(cc.shape[0]):\n",
    "    x1,y1 =  txx[i], tyy[i]\n",
    "    # only iterate over the indeces that are colliding and the upper diagonal in the collision matrix\n",
    "    jj = ii[ cc[i,:] * ii > i ] \n",
    "    for j in jj: \n",
    "        if cc[i,j]:\n",
    "            x2,y2 =  txx[j], tyy[j]\n",
    "            collision_pairs.append([(ID[i],x1,y1),(ID[j],x2,y2)])\n",
    "            \n",
    "            \n",
    "            \n",
    "for cp in collision_pairs:\n",
    "    plt.plot([cp[0][1],cp[1][1]],[cp[0][2],cp[1][2]],'r-')\n",
    "    #plt.plot(txx[ii_cal],tyy[ii_cal],'yo' , label='cal. star')\n",
    "\n",
    "print len(collision_pairs)\n",
    "\n",
    "plt.axis('equal')\n",
    "l = plt.legend()\n",
    "l.draw_frame(False)\n",
    "plt.xlabel(\"x [mm]\")\n",
    "plt.ylabel(\"y [mm]\")\n",
    "plt.xlim([-15,15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invert visibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a few statistics:\n",
    "# Number of rachable targets by type and\n",
    "# number of cobras that can observe any target.\n",
    "def invert_vis(visibilities):\n",
    "    \"\"\"\n",
    "    Invert visibility map, i.e. for each cobra list the observable targets\n",
    "    \"\"\"\n",
    "    ivisibilities = {}\n",
    "\n",
    "    cnt = 0\n",
    "    for v in visibilities:\n",
    "        t = v\n",
    "        cc = visibilities[v]\n",
    "\n",
    "        for c in cc:\n",
    "            if ivisibilities.has_key(c):\n",
    "                ivisibilities[c].append(v)\n",
    "            else:\n",
    "                ivisibilities[c] = [v]\n",
    "\n",
    "    return ivisibilities\n",
    "\n",
    "ivisibilities = invert_vis(visibilities)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsci_observable = 0\n",
    "ncal_observable = 0\n",
    "nsky_observable = 0\n",
    "\n",
    "for tid,v in visibilities.iteritems():\n",
    "    if len(v) > 0:\n",
    "        if class_dict[tid][:3] == 'cal':\n",
    "            ncal_observable += 1\n",
    "        elif class_dict[tid][:3] == 'sky':\n",
    "            nsky_observable += 1\n",
    "        elif class_dict[tid][:3] == 'sci':\n",
    "            nsci_observable += 1\n",
    "        #break\n",
    "            \n",
    "            \n",
    "print(\"{} targets positions in total.\".format(sum(ii_sci) ))\n",
    "print(\"{} cal. targets in total.\".format(sum(ii_cal) ))\n",
    "print(\"{} sky positions in total.\".format(sum(ii_sky) ))\n",
    "print(\"{} cobras have at least one target in reach.\".format(len(ivisibilities)))\n",
    "print(\"{} science targets\\n{} calibration targets, \\\n",
    "and \\n{} sky positions are in reach of at least one cobra.\".format(nsci_observable, ncal_observable, nsky_observable))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the ETS solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fil(xx,bb):\n",
    "    \"\"\"\n",
    "    Takes a list of objects and a boolean list of same length.\n",
    "    Retruns a list with all thos object for which the boolean\n",
    "    input list had a True.\n",
    "    \"\"\"\n",
    "    new = []\n",
    "    for x,b in zip(xx,bb):\n",
    "        if b: new.append(x)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "    \n",
    "ALGORITHM = \"new\"\n",
    "ALGORITHM = \"draining\"\n",
    "ALGORITHM = \"naive\"\n",
    "ALGORITHM = \"draining_closest\"\n",
    "\n",
    "ALL_ALGORITHM = [\"new\", \"draining\", \"naive\", \"draining_closest\"]\n",
    "\n",
    "for ALGORITHM in ALL_ALGORITHM:\n",
    "    print(\"ALGORITHM {}\".format(ALGORITHM))\n",
    "    NVISISTS = 10\n",
    "    ii = np.full_like(ID, True, dtype=bool)\n",
    "\n",
    "    # set priorities \n",
    "    priorities2 = np.array(priorities)\n",
    "    priorities2[ii_sci] = 5\n",
    "    priorities2[~ii_sci] = 1\n",
    "    priorities2 = priorities2.tolist()\n",
    "\n",
    "    with open(\"ets_results_{}.txt\".format(ALGORITHM), 'w') as f:\n",
    "        s = \"# algorithm: {}\\n\".format(ALGORITHM)\n",
    "        s += \"# total number of vistis: {}\\n\".format(NVISISTS)\n",
    "\n",
    "        s += \"# total number of observable science targets: {}\\n\".format(nsci_observable)\n",
    "        s += \"# total number of observable cal. targets: {}\\n\".format(ncal_observable)\n",
    "        s += \"# total number of observable sky positions: {}\\n\".format(nsky_observable)\n",
    "        s += \"{:3s} {:5s} {:5s} {:5s} {:5s}\\n\".format(\"V\", \"nsci\", \"ncal\", \"nsky\", \"nsci_total\")\n",
    "        f.write(s)\n",
    "\n",
    "        for v in range(NVISISTS):\n",
    "            s= \"\"\n",
    "\n",
    "            print(\"Visit {}\".format(v))\n",
    "            print(\" Number of remaining targets to observe: {}\".format(sum(ii)))\n",
    "\n",
    "            #print(\" Number of remaining cal. targets to observe: {}\".format( sum( np.array(types)[ii] == \"cal\" ) ))\n",
    "            #print(\" Number of remaining sky targets to observe: {}\".format( sum( np.array(types)[ii] == \"sky\" ) ))\n",
    "\n",
    "            start_time = time.time()\n",
    "            # perform target assignment using the \"draining\" algorithm, and return the list\n",
    "            # of assigned targets and which cobras were used to observe them.\n",
    "            #res = pyETS.getObs(fil(ets_target_pos,ii),fil(exp_times,ii),fil(priorities,ii),ets_cobras,\"draining_closest\")\n",
    "            res = pyETS.getObs(ets_target_pos,exp_times,priorities2,ets_cobras,ALGORITHM)\n",
    "            time_to_build = time.time() - start_time\n",
    "            pp(\" Time to solve: {:.4e} s\".format(time_to_build))\n",
    "\n",
    "\n",
    "\n",
    "            # figure which out of all potential science targets have been observed\n",
    "            # and mark them as observed\n",
    "            for r in res:\n",
    "                if types[r] == 'sci':\n",
    "                    priorities2[r] = 15\n",
    "                    ii[r] = False\n",
    "\n",
    "            # compute some statistics\n",
    "            nsci_observed = sum(np.array(types)[ res.keys() ] == 'sci')\n",
    "            ncal_observed = sum(np.array(types)[ res.keys() ] == 'cal')\n",
    "            nsky_observed = sum(np.array(types)[ res.keys() ] == 'sky')\n",
    "            print(\" Observed {} science targets, {} calibration targets and {} sky positions\"\\\n",
    "                  .format(nsci_observed, ncal_observed, nsky_observed))\n",
    "            N = len( res.items() )\n",
    "            #print(\" Observed {} targets.\".format(N))\n",
    "            nsci_observed_total = sum(ii_sci * ~ii)\n",
    "            print(\" Observed {} science targets in total.\".format(nsci_observed_total))\n",
    "            print(\"\")\n",
    "\n",
    "            s += \"{:3d} {:5d} {:5d} {:5d} {:5d}\\n\".format(v, nsci_observed, ncal_observed, nsky_observed, nsci_observed_total)\n",
    "            f.write(s)\n",
    "\n",
    "#np.any( np.array(types)[ res.keys() ] == 'cal' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot unobserved targets\n",
    "from numpy import array\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "f = plt.figure(figsize=[5,5])\n",
    "\n",
    "#plt.plot(fil(ra,~ii), fil(dec,~ii), '.', color='k')\n",
    "plt.plot(fil(ra,ii), fil(dec,ii), '.', color='r', alpha=0.1)\n",
    "\n",
    "plt.ylabel('dec [Deg]')\n",
    "plt.xlabel('ra [Deg]')\n",
    "#plt.axis(\"equal\")\n",
    "\n",
    "#plt.xlim([33.25,34.74])\n",
    "#plt.ylim([-5.25,-3.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute netflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define the cost function\n",
    "from numpy import inf\n",
    "\n",
    "cost_dict = {}\n",
    "# For each target class we define the cost of non-observation\n",
    "# and non-completion as a two-tuple. The cost of non-completion \n",
    "# is typically larger as partial completion of objects should be avoided.\n",
    "cost_dict['sci_P1'] = (1000.,1e9)\n",
    "cost_dict['sci_P2'] = (100.,1e9)\n",
    "cost_dict['sci_P3'] = (10.,1e9)\n",
    "\n",
    "# For the calibration objects we only define the cost\n",
    "# of non-observation as calibration targets only *need* to be visited once.\n",
    "# Note: The can of course be visited many times. But\n",
    "# for the calibration objects the real constraint is to have \n",
    "# at least N out of M observed in each exposure.\n",
    "# There is no requirement to revisit a specific calibration target.\n",
    "cost_dict['cal_P1'] = 10000.\n",
    "cost_dict['sky_P1'] = 10000.\n",
    "\n",
    "# Here we add higher cost to later visits. Ther should be one entry per visit.\n",
    "cost_dict['visits'] = [i*10. for i in np.arange(10)]\n",
    "\n",
    "# Here we discourage large cobra moves. The example here is a simple\n",
    "# linear function cost = A * move_distance \n",
    "# where the parameter A controls how quickly the cost increases as funciton of distance.\n",
    "#A = 250.\n",
    "A = 0.\n",
    "cost_dict['cobra_move'] = lambda d : d*A  \n",
    "\n",
    "\n",
    "\n",
    "# Here we define how at least many objects out of each class we want observed.\n",
    "supply_dict = {}\n",
    "# By setting science object to inf, we say we want them all.\n",
    "supply_dict['sci_P1'] = inf\n",
    "supply_dict['sci_P2'] = inf\n",
    "supply_dict['sci_P3'] = inf\n",
    "\n",
    "# need one calibration star per exposure\n",
    "supply_dict['cal_P1'] = 16 # inf = try to get as amny as  possible\n",
    "# need one sky positions per exposure\n",
    "supply_dict['sky_P1'] = 322 # inf = try to get as amny as  possible\n",
    "\n",
    "\n",
    "# need one calibration star per exposure\n",
    "supply_dict['cal_P1'] = 1# 12\n",
    "# need one sky positions per exposure\n",
    "supply_dict['sky_P1'] = 1# 329\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build the survey plan graph.\n",
    "\n",
    "from numpy import inf\n",
    "from pfs_netflow.survey_plan import buildSurveyPlan\n",
    "from pfs_netflow.plotting import plotSurveyPlan\n",
    "\n",
    "NVISITS = 2\n",
    "COBRAS = []\n",
    "\n",
    "\n",
    "# good minimal example\n",
    "RMAX = 10.\n",
    "CENTER = [0.,0.]\n",
    "name=\"minimal\"\n",
    "\n",
    "# intermediate example\n",
    "RMAX = 60.\n",
    "CENTER = [0.,0.]\n",
    "name=\"intermediate\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# good minimal example\n",
    "RMAX = 100.\n",
    "CENTER = [0.,0.]\n",
    "name=\"minimal\"\n",
    "\n",
    "\n",
    "\n",
    "# intermediate example\n",
    "RMAX = 150.\n",
    "CENTER = [-5.,90.]\n",
    "name=\"intermediate\"\n",
    "\n",
    "\n",
    "# smaller intermediate example\n",
    "RMAX = 75.\n",
    "CENTER = [-0.,0.]\n",
    "name=\"small\"\n",
    "\n",
    "# good minimal example\n",
    "RMAX = 25.\n",
    "CENTER = [-5.,90.]\n",
    "name=\"minimal\"\n",
    "\n",
    "# intermediate example\n",
    "RMAX = 150.\n",
    "CENTER = [0.,0.]\n",
    "name=\"intermediate\"\n",
    "\n",
    "# do them all!\n",
    "RMAX = 300.\n",
    "CENTER = [-0.,0.]\n",
    "name=\"all\"\n",
    "\n",
    "# good very minimal example\n",
    "RMAX = 25.\n",
    "CENTER = [-0.,0.]\n",
    "name=\"tiny\"\n",
    "\n",
    "\n",
    "\n",
    "# good very minimal example\n",
    "RMAX = 10.\n",
    "CENTER = [-0.,0.]\n",
    "name=\"tinytiny\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Creating graph ...\")\n",
    "g = buildSurveyPlan(cobras, targets, nreqvisits, visibilities, class_dict, cost_dict, supply_dict, NVISITS, \\\n",
    "                    RMAX, CENTER, COBRAS = COBRAS)\n",
    "print(\"Done.\")\n",
    "\n",
    "for c in g.sciTargetClasses:\n",
    "    \n",
    "    nsci = 0\n",
    "    nsci_reachable = 0\n",
    "    for t in g.sciTargetClasses[c].targets.itervalues():\n",
    "        if t.outarcs != []:\n",
    "            nsci += 1\n",
    "            nsci_reachable += 1\n",
    "        \n",
    "    print(\"Number of targets in {} is {}.\".format(c, nsci ) )\n",
    "    print(\"Number of observable targets in {} is {}.\".format(c, nsci_reachable ) )\n",
    "    \n",
    "\n",
    "ncal = 0\n",
    "ncal_reachable = 0\n",
    "for t in g.calTargetClasses['TClass_cal_P1_v0'].targets.itervalues():\n",
    "    if t.outarcs != []:\n",
    "        ncal += 1\n",
    "        ncal_reachable += 1\n",
    "print(\"Number of calibration stars: {}\".format(ncal) )\n",
    "print(\"Number of observable calibration stars: {}\".format( ncal_reachable )) \n",
    "            \n",
    "\n",
    "nsky = 0\n",
    "nsky_reachable = 0\n",
    "for t in g.calTargetClasses['TClass_sky_P1_v0'].targets.itervalues():\n",
    "    if t. outarcs != []:\n",
    "        nsky += 1\n",
    "        nsky_reachable += 1\n",
    "print(\"Number of sky positions: {}\".format(nsky) )\n",
    "print(\"Number of observable sky positions: {}\".format(nsky_reachable) )\n",
    "\n",
    "#if RMAX == 10. and False:\n",
    "#    plotSurveyPlan(g)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the LP problem\n",
    "from pfs_netflow.lp import buildLPProblem, computeStats, solve\n",
    "from pulp import LpStatus, value\n",
    "import time\n",
    "\n",
    "\n",
    "def setflows(g,flows):\n",
    "    for a in g.arcs.itervalues():\n",
    "        k = '{}={}'.format(a.startnode.id,a.endnode.id)\n",
    "        if flows.has_key(k):\n",
    "            a.flow = value(flows[k])\n",
    "\n",
    "\n",
    "    \n",
    "NCobras = len(g.cobras)\n",
    "NSciTargets = len(g.sciTargets)\n",
    "NCalTargets = len(g.calTargets)\n",
    "\n",
    "maxSeconds = 600.\n",
    "\n",
    "summary = \"\"\n",
    "summary += pp(\"NVISITS = {}\".format(NVISITS))\n",
    "summary += pp(\"Searching optimal strategy to observe in \")\n",
    "summary += pp(\" {} visits\".format(NVISITS))\n",
    "summary += pp(\" {} science targets\".format(NSciTargets))\n",
    "summary += pp(\" {} calib. targets\".format(NCalTargets/NVISITS))\n",
    "summary += pp(\" {} cobras\".format(NCobras))\n",
    "summary += pp(\"Will stop in any case after {} s.\".format(maxSeconds))\n",
    "\n",
    "\n",
    "summary += pp(\"num nodes: {}\".format(len(g.nodes)))\n",
    "summary += pp(\"num edges: {}\".format(len(g.arcs)))\n",
    "\n",
    "#visualizeSurveyPlan(g)\n",
    "\n",
    "summary += pp(\"Building LP problem ...\")\n",
    "start_time = time.time()\n",
    "prob, flows, cost = buildLPProblem(g, cat='Integer')\n",
    "#prob, flows, cost = buildLPProblem(g, cat='Continuous')\n",
    "time_to_build = time.time() - start_time\n",
    "summary += pp(\"Time to build model: {:.4e} s\".format(time_to_build))\n",
    "\n",
    "__ = prob.writeMPS(\"pfi_cosmo_{}_{}_visits_rand_nreq.mps\".format(name,NVISITS), rename=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pulp\n",
    "\n",
    "def compute_collision_flow_pairs(collision_pairs):\n",
    "    \"\"\"\n",
    "     Identifiy which flow variables correspond to which collision pairs.\n",
    "\n",
    "     This is not a nice piece of code, mostly because we need to treat science and\n",
    "     calibrations targets differently\n",
    "     What we do:\n",
    "     Loop over all collision pairs (science - science, science - cal, cal - cal)\n",
    "      then for each visit\n",
    "       look if they are actually part of the graph (in case we are dealing with a subregaion of the focal plane only we might ignore them)\n",
    "       identify the input flow arc (ther can be only one) for each of the two targets in the pair\n",
    "       add the flow pairs to a list\n",
    "     loop over all flow pairs and add a constraint equation\n",
    "    \"\"\" \n",
    "    flow_pairs = []\n",
    "\n",
    "    for cp in collision_pairs:\n",
    "        for visit in g.visits:\n",
    "            tid1 = cp[0][0]\n",
    "            tid2 = cp[1][0]\n",
    "\n",
    "            tvid1 = \"T_{}_v{}\".format(cp[0][0],visit)\n",
    "            tvid2 = \"T_{}_v{}\".format(cp[1][0],visit)\n",
    "\n",
    "            # science targets have targetVisit nodes\n",
    "            # calibrations targets do not (there ais a doublicate for each visits)\n",
    "            if g.calTargets.has_key(tvid1):\n",
    "                f1id = g.calTargets[tvid1].inarcs[0].id\n",
    "            elif g.targetVisits.has_key(tvid1):\n",
    "                f1id = g.targetVisits[tvid1].inarcs[0].id\n",
    "            else:\n",
    "                continue # this target is not part of the problem, probably did not survive RMAX cut\n",
    "\n",
    "            if g.calTargets.has_key(tvid2):\n",
    "                f2id = g.calTargets[tvid2].inarcs[0].id\n",
    "            elif g.targetVisits.has_key(tvid2):\n",
    "                f2id = g.targetVisits[tvid2].inarcs[0].id\n",
    "            else:\n",
    "                continue # this target is not part of the problem, probably did not survive RMAX cut\n",
    "\n",
    "\n",
    "            flow_pairs.append([f1id, f2id])\n",
    "    return flow_pairs\n",
    "  \n",
    "ENABLE_COLLISION_AVOIDANCE = True\n",
    "if ENABLE_COLLISION_AVOIDANCE:\n",
    "    flow_pairs = compute_collision_flow_pairs(collision_pairs)\n",
    "    print(\"Adding {} collision avoidance constraints.\".format(len(flow_pairs)))              \n",
    "    for fp in flow_pairs:\n",
    "        prob += pulp.lpSum( [ flows[ fp[0] ], flows[ fp[1] ] ] ) <= 1.\n",
    "\n",
    "__ = prob.writeMPS(\"pfi_cosmo_{}_{}_visits_rand_nreq_colldetect.mps\".format(name,NVISITS), rename=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# solve it!\n",
    "maxSeconds=2400.\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Solve problem!\n",
    "summary += pp(\"Solving LP problem ...\")\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "#status = solve(prob, maxSeconds=maxSeconds)\n",
    "status = solve(prob, solver=\"GUROBI\")\n",
    "\n",
    "\n",
    "time_to_solve = time.time() - start_time\n",
    "summary += pp(\"Solve status is [{}].\".format( LpStatus[status] ))\n",
    "summary += pp(\"Time to solve: {:.4e} s\".format(time_to_solve))\n",
    "\n",
    "stats = computeStats(g, flows, cost)\n",
    "\n",
    "summary += pp(\"{} = {}\".format('Value of cost function',value(stats.cost) ) )\n",
    "summary += pp(\"[{}] out of {} science targets get observed.\".format(int(stats.NSciObs),NSciTargets))\n",
    "summary += pp(\"For {} out of these all required exposures got allocated.\".format(stats.NSciComplete))\n",
    "summary += pp(\"{} targets get sent down the overflow arc.\".format(stats.Noverflow))\n",
    "summary += pp(\"{} out of {} cobras observed a target in one or more exposures.\".format(stats.Ncobras_used, NCobras ))\n",
    "summary += pp(\"{} cobras observed a target in all exposures.\".format(stats.Ncobras_fully_used))\n",
    "\n",
    "setflows(g,flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if really no colliding targets were observed\n",
    "# This needs to be added to the survey plan and buildLPProblem methods.\n",
    "#\n",
    "import pulp\n",
    "from pulp import value\n",
    "\n",
    "\n",
    "flow_pairs = compute_collision_flow_pairs(collision_pairs)\n",
    " \n",
    "NCOLL = 0\n",
    "for fp in flow_pairs:\n",
    "    \n",
    "    if value( flows[ fp[0] ] ) > 0. and value( flows[ fp[1] ] ) > 0.:\n",
    "        #print(\"{} {} in collision\".format(fp[0],fp[1]))\n",
    "        NCOLL += 1\n",
    "                             \n",
    "print(\"Detected {} collisions\".format(NCOLL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value( flows[ fp[1] ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pfs_netflow.plotting import plotFocalPlane\n",
    "def setflows(g,flows):\n",
    "    for a in g.arcs.itervalues():\n",
    "        k = '{}={}'.format(a.startnode.id,a.endnode.id)\n",
    "        if flows.has_key(k):\n",
    "            a.flow = value(flows[k])\n",
    "            \n",
    "if True:\n",
    "    from pfs_netflow.plotting import plotFocalPlane\n",
    "\n",
    "    plotFocalPlane(g, visit=1, W=25)\n",
    "    plotSurveyPlan(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSurveyPlan(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare Cobra/Target pairs to run trajectory collision detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "visit = 0\n",
    " \n",
    "# initialize assigment list with Null\n",
    "# as required by the collision simulator code.\n",
    "assignments = OrderedDict()\n",
    "for c in g.cobras.itervalues():\n",
    "    assignments[c.id] = 'Null'\n",
    "\n",
    "# Now find which cobras have been assigned to which targets. \n",
    "# Loop over all targetVisit to CobraVisit arcs.Filter for those that correspond to the current visit.\n",
    "for a in filter(lambda x : x.visit == visit, g.targetVisitToCobraVisitArcs.itervalues()):\n",
    "    \n",
    "    if a.flow > 0.:\n",
    "        t = a.startnode.target\n",
    "        c = a.endnode.cobra \n",
    "        assignments[c.id] = t.id\n",
    "        \n",
    "for cid,tid in assignments.iteritems():\n",
    "    print(\"{:6s} observes {:10s}\".format(cid, tid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed to collision code\n",
    "import numpy as np\n",
    "import time as time\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/mxhf/work/MPE/pfs/src/ics_cobraOps/python\")\n",
    "\n",
    "import ics.cobraOps.plotUtils as plotUtils\n",
    "import ics.cobraOps.targetUtils as targetUtils\n",
    "\n",
    "from ics.cobraOps.Bench import Bench\n",
    "from ics.cobraOps.CobrasCalibrationProduct import CobrasCalibrationProduct\n",
    "from ics.cobraOps.CollisionSimulator import CollisionSimulator\n",
    "from ics.cobraOps.DistanceTargetSelector import DistanceTargetSelector\n",
    "from ics.cobraOps.RandomTargetSelector import RandomTargetSelector\n",
    "\n",
    "# Create the bench instanceroduct)\n",
    "#bench = Bench(layout=\"full\", calibrationProduct=calibrationP\n",
    "cpos = [ [ complex(g.cobras[cid].x , g.cobras[cid].y) ] for cid in assignments]\n",
    "bench = Bench(cobraCenters=np.array( cpos ))\n",
    "\n",
    "print(\"Number of cobras:\", bench.cobras.nCobras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the total number of targets based on the bench properties\n",
    "    medianPatrolAreaRadius = np.median(bench.cobras.rMax)\n",
    "\n",
    "    \n",
    "    nTargets = int(np.ceil(density * (bench.radius / medianPatrolAreaRadius) ** 2))\n",
    "    \n",
    "    # Calculate the uniformly distributed target positions\n",
    "    ang = 2 * np.pi * np.random.random(nTargets)\n",
    "    radius = bench.radius * np.sqrt(np.random.random(nTargets))\n",
    "    targetPositions = bench.center + radius * np.exp(1j * ang)\n",
    "    \n",
    "    return TargetGroup(targetPositions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the targets\n",
    "targets = targetUtils.generateRandomTargets(targetDensity, bench)\n",
    "print(\"Number of simulated targets:\", targets.nTargets)\n",
    "\n",
    "# Select the targets\n",
    "selector = DistanceTargetSelector(bench, targets)\n",
    "selector.run()\n",
    "selectedTargets = selector.getSelectedTargets()\n",
    "\n",
    "# Simulate an observation\n",
    "start = time.time()\n",
    "simulator = CollisionSimulator(bench, selectedTargets)\n",
    "simulator.run()\n",
    "print(\"Number of cobras involved in collisions:\", simulator.nCollisions)\n",
    "print(\"Number of cobras unaffected by end collisions: \", simulator.nCollisions - simulator.nEndPointCollisions)\n",
    "print(\"Total simulation time (s):\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics on cobra motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# array of all distances for all possible target/cobra pairs\n",
    "dd =  np.array( [ a.d for a in g.targetVisitToCobraVisitArcs.itervalues()] )\n",
    "# array of flows for all possible target/cobra pairs\n",
    "ff =  np.array( [ value(flows[a.id]) for a in g.targetVisitToCobraVisitArcs.itervalues()] )\n",
    "\n",
    "# caclulate mean cobra move distance\n",
    "ii = ff > 0.\n",
    "mn_movedist = np.mean( dd[ii] )\n",
    "min_movedist = np.min( dd[ii] )\n",
    "max_movedist = np.max( dd[ii] )\n",
    "std_movedist = np.std( dd[ii] )\n",
    "\n",
    "print(\"mn_movedist =  {:.3f}mm\".format(mn_movedist) )\n",
    "print(\"min_movedist = {:.3f}mm\".format(min_movedist) )\n",
    "print(\"max_movedist = {:.3f}mm\".format(max_movedist) )\n",
    "print(\"std_movedist = {:.3f}mm\".format(std_movedist) )\n",
    "\n",
    "\n",
    "cm = np.sum([ a.cost * value(flows[a.id]) for a in g.targetVisitToCobraVisitArcs.itervalues() ])\n",
    "\n",
    "print(\"cost from moves = {}\".format(cm) )\n",
    "\n",
    "\n",
    "plt.hist( dd[ii] )\n",
    "plt.xlabel(\"d[mm]\")\n",
    "plt.ylabel(\"N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performace evaluations observed targets vs. number of visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsci_observed_total = 0\n",
    "\n",
    "\n",
    "with open(\"nwf_results_nvisits{}_early_obs2.txt\".format(NVISITS), 'w') as f:\n",
    "    s  = \"# algorithm: {}\\n\".format(\"netflow\")\n",
    "    s += \"# total number of vistis: {}\\n\".format(NVISISTS)\n",
    "\n",
    "    s += \"# total number of observable science targets: {}\\n\".format(nsci_observable)\n",
    "    s += \"# total number of observable cal. targets: {}\\n\".format(ncal_observable)\n",
    "    s += \"# total number of observable sky positions: {}\\n\".format(nsky_observable)\n",
    "    s += \"{:3s} {:5s} {:5s} {:5s} {:5s}\\n\".format(\"V\", \"nsci\", \"ncal\", \"nsky\", \"nsci_total\")\n",
    "    f.write(s)\n",
    "\n",
    "    for visit in g.visits:\n",
    "        print(\"Visit {}\".format(visit))\n",
    "        nsci = 0\n",
    "        ncal = 0\n",
    "        nsky = 0\n",
    "        for a in g.arcs.itervalues():\n",
    "            n1,n2 = a.startnode,a.endnode\n",
    "\n",
    "            if a.flow > 0.:\n",
    "                #print n1,n2, a.flow, n2.visit\n",
    "                #print type(n2) == dm.CobraVisit , n2.visit == visit , type(n1) == dm.TargetVisit\n",
    "                #break\n",
    "                if type(n2) == dm.CobraVisit and n2.visit == visit and type(n1) == dm.TargetVisit:\n",
    "                        nsci += 1\n",
    "                        nsci_observed_total += 1\n",
    "                if type(n2) == dm.CobraVisit and n2.visit == visit and type(n1) == dm.CalTarget:\n",
    "                        try:\n",
    "                            if class_dict[ n1.id[2:-3] ][:3] == \"sky\":\n",
    "                                nsky += 1\n",
    "\n",
    "                            else:\n",
    "                                ncal += 1 \n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "        s = \"{:3d} {:5d} {:5d} {:5d} {:5d}\\n\".format(visit, nsci, ncal, nsky, nsci_observed_total)\n",
    "        f.write(s)\n",
    "        \n",
    "        print(\" Observed {} science targets, {} calibration targets and {} sky positions.\".format(nsci, ncal, nsky))\n",
    "        print(\" Observed {} science targets in total.\".format(nsci_observed_total))\n",
    "        #print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.targetToTargetVisitArcs\n",
    "\n",
    "value( flows['T_C000996->T_C000996_v0'.replace(\"->\",\"=\")] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfs_netflow.plotting import plotFocalPlane\n",
    "def setflows(g,flows):\n",
    "    for a in g.arcs.itervalues():\n",
    "        k = '{}={}'.format(a.startnode.id,a.endnode.id)\n",
    "        if flows.has_key(k):\n",
    "            a.flow = value(flows[k])\n",
    "            \n",
    "if False:\n",
    "    from pfs_netflow.plotting import plotFocalPlane\n",
    "\n",
    "    plotFocalPlane(g, visit=1, W=20)\n",
    "    plotSurveyPlan(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsci = sum( [class_dict[t][:3] == \"sci\" for t in targets] )\n",
    "ncal = sum( [class_dict[t][:3] == \"cal\" for t in targets] )\n",
    "nsky = sum( [class_dict[t][:3] == \"sky\" for t in targets] )\n",
    "\n",
    "sum( [class_dict[t][:3] == \"cal\" for t in targets] )\n",
    "\n",
    "\n",
    "print(\"{} targets positions in total.\".format( nsci ))\n",
    "print(\"{} cal. targets in total.\".format( ncal ))\n",
    "print(\"{} sky positions in total.\".format( nsky ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# performance comparison ETS vs. netflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import ascii\n",
    "\n",
    "nwf_results_nvisits = {}\n",
    "#nwf_results_nvisits[12] = ascii.read(\"nwf_results_nvisits12.txt\")\n",
    "#nwf_results_nvisits[12] = ascii.read(\"nwf_results_nvisits12.txt\")\n",
    "nwf_results_nvisits[10] = ascii.read(\"nwf_results_nvisits10_early_obs1.txt\")\n",
    "#nwf_results_nvisits[9] = ascii.read(\"nwf_results_nvisits9.txt\")\n",
    "#nwf_results_nvisits[8] = ascii.read(\"nwf_results_nvisits8.txt\")\n",
    "#nwf_results_nvisits[7] = ascii.read(\"nwf_results_nvisits7.txt\")\n",
    "#nwf_results_nvisits[6] = ascii.read(\"nwf_results_nvisits6.txt\")\n",
    "#nwf_results_nvisits[5] = ascii.read(\"nwf_results_nvisits5.txt\")\n",
    "#nwf_results_nvisits[4] = ascii.read(\"nwf_results_nvisits4.txt\")\n",
    "#nwf_results_nvisits[3] = ascii.read(\"nwf_results_nvisits3.txt\")\n",
    "#nwf_results_nvisits[2] = ascii.read(\"nwf_results_nvisits2.txt\")\n",
    "\n",
    "ets_results = {}\n",
    "ets_results[\"draining_closest\"] = ascii.read(\"ets_results_draining_closest.txt\")\n",
    "ets_results[\"draining\"] = ascii.read(\"ets_results_draining.txt\")\n",
    "ets_results[\"naive\"] = ascii.read(\"ets_results_naive.txt\")\n",
    "ets_results[\"new\"] = ascii.read(\"ets_results_new.txt\")\n",
    "\n",
    "#ascii.read(\"ets_results_draining_closest.txt\",format\n",
    "\n",
    "f = plt.figure(figsize=[8,8])\n",
    "\n",
    "for alg in ets_results:\n",
    "    plt.plot(ets_results[alg]['V']+1, ets_results[alg]['nsci_total'],'o-', label=alg)\n",
    "\n",
    "#for nvisits in nwf_results_nvisits:\n",
    "#    plt.plot(nwf_results_nvisits[nvisits]['V']+1, nwf_results_nvisits[nvisits]['nsci_total'],'ks-', label=alg, color='grey', ms=8)\n",
    "\n",
    "nvisits = 10\n",
    "plt.plot(nwf_results_nvisits[nvisits]['V']+1, nwf_results_nvisits[nvisits]['nsci_total'],'ks-', label=\"netflow\", color='grey', ms=8)\n",
    "\n",
    "l = plt.legend()\n",
    "l.draw_frame(False)\n",
    "\n",
    "plt.axhline(nsci_observable,ls=\":\",c='k')\n",
    "plt.text(1,nsci_observable+50,\"max # science targets observable\".format(nsci_observable),ha='left',va='bottom')\n",
    "plt.ylabel(\"# science targets observed\")\n",
    "plt.xlabel(\"visit\")\n",
    "plt.ylim([500,8200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New & auxiliary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # test output for other solvers\n",
    "    # build problem save to MPS\n",
    "    import time\n",
    "\n",
    "\n",
    "    summary += pp(\"Building LP problem ...\")\n",
    "    start_time = time.time()\n",
    "    #prob, flows, cost = buildLPProblem(g, cat='Integer')\n",
    "    prob, flows, cost = buildLPProblem(g, cat='Continuous')\n",
    "    time_to_build = time.time() - start_time\n",
    "    summary += pp(\"Time to build model: {:.4e} s\".format(time_to_build))\n",
    "\n",
    "    prob.writeMPS(\"pfi_cosmo_{}_{}_visits_rand_nreq.mps\".format(name,NVISITS), rename=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RSEP = 5.\n",
    "\n",
    "if RSEP > 0.:\n",
    "    print(\"Finding collision pairs ...\")\n",
    "    tt = np.array( [t for t in g.targets.itervalues()] )\n",
    "    tt_xy = [ (g.targets[t].x,g.targets[t].y) for t in g.targets]\n",
    "\n",
    "    N = len(tt)\n",
    "\n",
    "    from scipy.spatial import distance\n",
    "    # calculat collisions from all pairwise separations\n",
    "    colls = distance.cdist(tt_xy, tt_xy, 'euclidean') < RSEP\n",
    "    # set lower diagonal to False, if we know that A collides with B already\n",
    "    # then we don't need to take into account that B collides with A\n",
    "    colls[ np.tril_indices(N) ] = False \n",
    "\n",
    "    coll_pairs = []\n",
    "    for i,t1 in enumerate(tt):\n",
    "        for t2 in tt[ colls[i] ].tolist():\n",
    "            coll_pairs.append([t1,t2])\n",
    "            #print t1.id,t2.id\n",
    "\n",
    "    print( \"Found {} collision pairs.\".format(len( coll_pairs )) )\n",
    "\n",
    "    #for tid,t in tt:\n",
    "    #    prob += pulp.lpSum( [ flows['{}={}'.format(a.startnode.id,a.endnode.id)] for a in t.outarcs]) <= 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "t1,t2 = coll_pairs[i]\n",
    "\n",
    "print type(t1) == SciTarget\n",
    "print type(t1) == CalTarget\n",
    "\n",
    "t2.outarcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check, make sure all flows are integer:\n",
    "allflows = []\n",
    "for a in g.arcs.itervalues():\n",
    "    k = '{}={}'.format(a.startnode.id,a.endnode.id)\n",
    "    if flows.has_key(k):\n",
    "        allflows.append(value(flows[k]))\n",
    "\n",
    "print(\"All flows are: integer {}\".format(all( unique(allflows)%1 == 0 )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    # plot solution\n",
    "    for a in g.arcs.itervalues():\n",
    "        k = '{}={}'.format(a.startnode.id,a.endnode.id)\n",
    "        if flows.has_key(k):\n",
    "            a.flow = value(flows[k])\n",
    "    plotSurveyPlan(g)\n",
    "    #return g, stats, time_to_build, time_to_solve, status, prob, flows, cost, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    def rescue_code(function):\n",
    "        import inspect\n",
    "        get_ipython().set_next_input(\"\".join(inspect.getsourcelines(function)[0]))\n",
    "\n",
    "    rescue_code(buildSurveyPlan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Old collision detection code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# find collision pairs\n",
    "\n",
    "`\n",
    "from scipy.spatial.distance import cdist\n",
    "fiber_collision_radius = 1.\n",
    "\n",
    "\n",
    "f = plt.figure(figsize=[20,20])\n",
    "plt.subplot()\n",
    "\n",
    "\n",
    "txx = np.array( [t.x for tid, t in g.targets.iteritems()] )\n",
    "tyy = np.array( [t.y for tid, t in g.targets.iteritems()] )\n",
    "\n",
    "_ii_sci = map( lambda x : x.startswith('sci') , tclasses )\n",
    "_ii_sky = map( lambda x : x.startswith('sky') , tclasses )\n",
    "_ii_cal = map( lambda x : x.startswith('cal') , tclasses )\n",
    "\n",
    "\n",
    "plt.plot(txx,tyy,'.', ms=1, label='science')\n",
    "#plt.plot(txx[_ii_sky],tyy[_ii_sky],'b.' , label='sky')\n",
    "#plt.plot(txx[_ii_cal],tyy[_ii_cal],'yo' , label='cal. star')\n",
    "\n",
    "\n",
    "N = len(g.targets)\n",
    "points = zip(txx,tyy)\n",
    "Y = cdist( points[:N], points[:N] )\n",
    "\n",
    "\n",
    "\n",
    "# any target separation that is smaller than 2 x the collision radius will be flagged a s collision\n",
    "cc = Y <= (fiber_collision_radius*2.) \n",
    "\n",
    "ncoll = int( (np.sum(cc.flatten()) - N)/2. )\n",
    "\n",
    "print (\"Found  {:d} collision pairs.\".format( ncoll  ))\n",
    "\n",
    "\n",
    "# identify collision pairs\n",
    "collision_pairs = []\n",
    "# array of indices\n",
    "ii = np.arange(N)\n",
    "for i in range(cc.shape[0]):\n",
    "    x1,y1 =  txx[i], tyy[i]\n",
    "    # only iterate over the indeces that are colliding and the upper diagonal in the collision matrix\n",
    "    jj = ii[ cc[i,:] * ii > i ] \n",
    "    for j in jj: \n",
    "        if cc[i,j]:\n",
    "            x2,y2 =  txx[j], tyy[j]\n",
    "            collision_pairs.append([(ID[i],x1,y1),(ID[j],x2,y2)])\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "for cp in collision_pairs:\n",
    "    plt.plot([cp[0][1],cp[1][1]],[cp[0][2],cp[1][2]],'r-')\n",
    "    #plt.plot(txx[ii_cal],tyy[ii_cal],'yo' , label='cal. star')\n",
    "\n",
    "print len(collision_pairs)\n",
    "\n",
    "plt.axis('equal')\n",
    "l = plt.legend()\n",
    "l.draw_frame(False)\n",
    "plt.xlabel(\"x [mm]\")\n",
    "plt.ylabel(\"y [mm]\")\n",
    "plt.xlim([-50,50])\n",
    "\n",
    "cc = Y < 6.\n",
    "print sum(cc.flatten())"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
